{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "969f72f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#\"data/preprocessed/train/sentectes.txt\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open (\"data/preprocessed/train/sentences.txt\", encoding = \"utf8\") as text:\n",
    "    \n",
    "    data = text.readlines()\n",
    "    string = ''.join([str(item) for item in data])\n",
    "\n",
    "    doc = nlp(string)\n",
    "\n",
    "\n",
    "nouns =  [chunk.text for chunk in doc.noun_chunks]\n",
    "#print(f\"Noun = {len(nouns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af604246",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f2320f9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens 16130\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Tokens\n",
    "'''\n",
    "count = 0\n",
    "for token in doc:\n",
    "    #print(token.tag_)\n",
    "    count+=1\n",
    "\n",
    "print(f\"Number of tokens {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e05852c",
   "metadata": {},
   "source": [
    "### Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3249b074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of types 3746\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Types\n",
    "'''\n",
    "count = 0\n",
    "unique = []\n",
    "\n",
    "for words in doc:\n",
    "\n",
    "    unique.append(words.text)\n",
    "    \n",
    "unique = np.unique(unique)    \n",
    "\n",
    "print(f\"The number of types {len(unique)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832d57fb",
   "metadata": {},
   "source": [
    "### Number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b3776e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12707\n"
     ]
    }
   ],
   "source": [
    "skip = [\"PUNCT\", \"SYM\", \"X\", \"SPACE\", \"NUM\"]\n",
    "word_list = []\n",
    "for token in doc:\n",
    "    if token.pos_ not in skip:\n",
    "        if token.lemma_.isalpha():\n",
    "            word_list.append(token.text)\n",
    "\n",
    "print(len(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2af7b4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of words 12707\n"
     ]
    }
   ],
   "source": [
    "print(f\"The total number of words {len(word_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d71c53",
   "metadata": {},
   "source": [
    "### Average number of words per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "09f1ae44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average words per sentence is 17.83426183844011\n"
     ]
    }
   ],
   "source": [
    "word_count_list = []\n",
    "\n",
    "counter = 0\n",
    "wordcount = 0\n",
    "sentcount = 0\n",
    "for sent in doc.sents:\n",
    "    \n",
    "    for token in sent:\n",
    "        if token.text.isalpha():\n",
    "            wordcount+=1\n",
    "    sentcount+=1\n",
    "\n",
    "print(f\"The average words per sentence is {wordcount/sentcount}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68245c7e",
   "metadata": {},
   "source": [
    "### Average word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "201c6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lengths = []\n",
    "\n",
    "for i in word_list:\n",
    "    word_lengths.append(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d2207a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average word length is 4.972692216888329 +/- 2.5850988048015324\n"
     ]
    }
   ],
   "source": [
    "print(f\"The average word length is {np.mean(word_lengths)} +/- {np.std(word_lengths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e20ec2f",
   "metadata": {},
   "source": [
    "## Word Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd949d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "33c972d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_dict = {}\n",
    "\n",
    "for token in doc:\n",
    "    if token.tag_ in universal_dict.keys():\n",
    "        universal_dict[token.tag_].append(token)\n",
    "    else:\n",
    "        universal_dict[token.tag_] =[]\n",
    "        universal_dict[token.tag_].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b315e9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['NNS', 'VBP', 'VBN', 'TO', 'VB', 'CD', ',', 'CC', 'IN', 'DT', 'HYPH', 'NN', 'JJ', '.', '_SP', 'PRP', 'VBD', 'NNP', 'RP', 'WRB', 'MD', 'RB', 'JJR', 'VBG', 'VBZ', 'PRP$', \"''\", 'WP', 'RBS', 'POS', 'NNPS', ':', 'WDT', 'EX', '-LRB-', '-RRB-', 'UH', 'RBR', 'JJS', '$', 'NFP', 'XX', 'PDT', 'SYM', 'FW', '``'])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universal_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "bb54de57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774\n",
      "202\n",
      "500\n",
      "182\n",
      "328\n",
      "357\n",
      "699\n",
      "347\n",
      "1745\n",
      "1378\n",
      "105\n",
      "2074\n",
      "868\n",
      "655\n",
      "653\n",
      "338\n",
      "660\n",
      "2063\n",
      "40\n",
      "46\n",
      "93\n",
      "451\n",
      "23\n",
      "296\n",
      "301\n",
      "145\n",
      "258\n",
      "38\n",
      "18\n",
      "111\n",
      "35\n",
      "63\n",
      "74\n",
      "14\n",
      "57\n",
      "57\n",
      "7\n",
      "18\n",
      "27\n",
      "5\n",
      "8\n",
      "6\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "vals = []\n",
    "\n",
    "for key in universal_dict.keys():\n",
    "    print(int(len(universal_dict[key])))\n",
    "    vals.append([key, int(len(universal_dict[key]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "09d363ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'774'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "404e1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "3e3f84ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(children, 1),\n",
       " (years, 1),\n",
       " (concentrations, 1),\n",
       " (spores, 1),\n",
       " (petridishes, 1),\n",
       " (borders, 1),\n",
       " (children, 1),\n",
       " (demands, 1),\n",
       " (authorities, 1),\n",
       " (people, 1),\n",
       " (troops, 1),\n",
       " (tanks, 1),\n",
       " (criteria, 1),\n",
       " (terms, 1),\n",
       " (polls, 1),\n",
       " (injuries, 1),\n",
       " (deaths, 1),\n",
       " (attacks, 1),\n",
       " (people, 1),\n",
       " (ribs, 1),\n",
       " (tonnes, 1),\n",
       " (people, 1),\n",
       " (children, 1),\n",
       " (daughters, 1),\n",
       " (corpses, 1),\n",
       " (plays, 1),\n",
       " (charges, 1),\n",
       " (suspects, 1),\n",
       " (hours, 1),\n",
       " (prosecutors, 1),\n",
       " (actions, 1),\n",
       " (interests, 1),\n",
       " (methods, 1),\n",
       " (negotiations, 1),\n",
       " (data, 1),\n",
       " (radars, 1),\n",
       " (airports, 1),\n",
       " (counts, 1),\n",
       " (vehicles, 1),\n",
       " (passengers, 1),\n",
       " (plans, 1),\n",
       " (ants, 1),\n",
       " (species, 1),\n",
       " (lives, 1),\n",
       " (diplomats, 1),\n",
       " (agencies, 1),\n",
       " (victims, 1),\n",
       " (families, 1),\n",
       " (muscles, 1),\n",
       " (decisions, 1),\n",
       " (leaders, 1),\n",
       " (elements, 1),\n",
       " (taxes, 1),\n",
       " (penalties, 1),\n",
       " (reforms, 1),\n",
       " (flights, 1),\n",
       " (graves, 1),\n",
       " (parents, 1),\n",
       " (nations, 1),\n",
       " (exercises, 1),\n",
       " (troops, 1),\n",
       " (considerations, 1),\n",
       " (ants, 1),\n",
       " (toxins, 1),\n",
       " (parasites, 1),\n",
       " (bars, 1),\n",
       " (customs, 1),\n",
       " (deals, 1),\n",
       " (countries, 1),\n",
       " (seconds, 1),\n",
       " (threats, 1),\n",
       " (fines, 1),\n",
       " (threats, 1),\n",
       " (people, 1),\n",
       " (rights, 1),\n",
       " (Researchers, 1),\n",
       " (subjects, 1),\n",
       " (mice, 1),\n",
       " (Police, 1),\n",
       " (migrants, 1),\n",
       " (cases, 1),\n",
       " (ties, 1),\n",
       " (policies, 1),\n",
       " (races, 1),\n",
       " (events, 1),\n",
       " (troops, 1),\n",
       " (weeks, 1),\n",
       " (ants, 1),\n",
       " (measures, 1),\n",
       " (refugees, 1),\n",
       " (traffickers, 1),\n",
       " (doctors, 1),\n",
       " (Police, 1),\n",
       " (bodies, 1),\n",
       " (people, 1),\n",
       " (riots, 1),\n",
       " (performances, 1),\n",
       " (lips, 1),\n",
       " (members, 1),\n",
       " (others, 1),\n",
       " (years, 1),\n",
       " (attacks, 1),\n",
       " (years, 1),\n",
       " (officers, 1),\n",
       " (citizens, 1),\n",
       " (funds, 1),\n",
       " (purposes, 1),\n",
       " (weeks, 1),\n",
       " (servers, 1),\n",
       " (parties, 1),\n",
       " (owners, 1),\n",
       " (days, 1),\n",
       " (weeks, 1),\n",
       " (ants, 1),\n",
       " (insects, 1),\n",
       " (km, 1),\n",
       " (miles, 1),\n",
       " (data, 1),\n",
       " (ants, 1),\n",
       " (ones, 1),\n",
       " (tanks, 1),\n",
       " (victims, 1),\n",
       " (workings, 1),\n",
       " (men, 1),\n",
       " (ants, 1),\n",
       " (ants, 1),\n",
       " (months, 1),\n",
       " (ants, 1),\n",
       " (results, 1),\n",
       " (loudspeakers, 1),\n",
       " (hours, 1),\n",
       " (broadcasts, 1),\n",
       " (ants, 1),\n",
       " (residents, 1),\n",
       " (people, 1),\n",
       " (foreigners, 1),\n",
       " (troops, 1),\n",
       " (crashes, 1),\n",
       " (riots, 1),\n",
       " (governments, 1),\n",
       " (prisons, 1),\n",
       " (prisons, 1),\n",
       " (convicts, 1),\n",
       " (units, 1),\n",
       " (inmates, 1),\n",
       " (Dozens, 1),\n",
       " (refugees, 1),\n",
       " (workers, 1),\n",
       " (passengers, 1),\n",
       " (personnel, 1),\n",
       " (circumstances, 1),\n",
       " (pages, 1),\n",
       " (hours, 1),\n",
       " (trucks, 1),\n",
       " (tanks, 1),\n",
       " (agencies, 1),\n",
       " (millions, 1),\n",
       " (pounds, 1),\n",
       " (hours, 1),\n",
       " (bodies, 1),\n",
       " (ants, 1),\n",
       " (thoughts, 1),\n",
       " (radars, 1),\n",
       " (points, 1),\n",
       " (crashes, 1),\n",
       " (men, 1),\n",
       " (Concerns, 1),\n",
       " (convictions, 1),\n",
       " (lawyers, 1),\n",
       " (members, 1),\n",
       " (members, 1),\n",
       " (participants, 1),\n",
       " (migrants, 1),\n",
       " (regions, 1),\n",
       " (sentences, 1),\n",
       " (bombings, 1),\n",
       " (1970s, 1),\n",
       " (1980s, 1),\n",
       " (individuals, 1),\n",
       " (offenders, 1),\n",
       " (reasons, 1),\n",
       " (others, 1),\n",
       " (aerodynamics, 1),\n",
       " (mice, 1),\n",
       " (times, 1),\n",
       " (reports, 1),\n",
       " (pieces, 1),\n",
       " (feet, 1),\n",
       " (feet, 1),\n",
       " (days, 1),\n",
       " (attacks, 1),\n",
       " (dozens, 1),\n",
       " (refugees, 1),\n",
       " (rebels, 1),\n",
       " (parties, 1),\n",
       " (opponents, 1),\n",
       " (debates, 1),\n",
       " (criteria, 1),\n",
       " (polls, 1),\n",
       " (relations, 1),\n",
       " (participants, 1),\n",
       " (incidents, 1),\n",
       " (buses, 1),\n",
       " (dozens, 1),\n",
       " (stations, 1),\n",
       " (protests, 1),\n",
       " (quotas, 1),\n",
       " (cities, 1),\n",
       " (workers, 1),\n",
       " (data, 1),\n",
       " (ants, 1),\n",
       " (theories, 1),\n",
       " (candidates, 1),\n",
       " (debates, 1),\n",
       " (tributes, 1),\n",
       " (ants, 1),\n",
       " (interviews, 1),\n",
       " (attempts, 1),\n",
       " (authorities, 1),\n",
       " (confessions, 1),\n",
       " (Insects, 1),\n",
       " (animals, 1),\n",
       " (hours, 1),\n",
       " (ants, 1),\n",
       " (ants, 1),\n",
       " (lots, 1),\n",
       " (animals, 1),\n",
       " (resources, 1),\n",
       " (friends, 1),\n",
       " (couples, 1),\n",
       " (residents, 1),\n",
       " (thoughts, 1),\n",
       " (plates, 1),\n",
       " (pictures, 1),\n",
       " (ants, 1),\n",
       " (nests, 1),\n",
       " (hosts, 1),\n",
       " (debates, 1),\n",
       " (criteria, 1),\n",
       " (candidates, 1),\n",
       " (experiments, 1),\n",
       " (organizations, 1),\n",
       " (results, 1),\n",
       " (internationals, 1),\n",
       " (police, 1),\n",
       " (species, 1),\n",
       " (species, 1),\n",
       " (pillars, 1),\n",
       " (immigrants, 1),\n",
       " (candidates, 1),\n",
       " (criteria, 1),\n",
       " (polls, 1),\n",
       " (pillars, 1),\n",
       " (immigrants, 1),\n",
       " (findings, 1),\n",
       " (comparisons, 1),\n",
       " (zombies, 1),\n",
       " (animals, 1),\n",
       " (squares, 1),\n",
       " (ants, 1),\n",
       " (covers, 1),\n",
       " (criteria, 1),\n",
       " (debates, 1),\n",
       " (ants, 1),\n",
       " (communications, 1),\n",
       " (assets, 1),\n",
       " (interests, 1),\n",
       " (authorities, 1),\n",
       " (names, 1),\n",
       " (ages, 1),\n",
       " (victims, 1),\n",
       " (months, 1),\n",
       " (missiles, 1),\n",
       " (plans, 1),\n",
       " (charges, 1),\n",
       " (allegations, 1),\n",
       " (arguments, 1),\n",
       " (brothers, 1),\n",
       " (allegations, 1),\n",
       " (passengers, 1),\n",
       " (families, 1),\n",
       " (powers, 1),\n",
       " (ants, 1),\n",
       " (pictures, 1),\n",
       " (times, 1),\n",
       " (ants, 1),\n",
       " (data, 1),\n",
       " (proceedings, 1),\n",
       " (rights, 1),\n",
       " (rounds, 1),\n",
       " (Animals, 1),\n",
       " (strains, 1),\n",
       " (ants, 1),\n",
       " (resistances, 1),\n",
       " (troops, 1),\n",
       " (species, 1),\n",
       " (poems, 1),\n",
       " (sons, 1),\n",
       " (reasons, 1),\n",
       " (Police, 1),\n",
       " (trackers, 1),\n",
       " (vehicles, 1),\n",
       " (months, 1),\n",
       " (ants, 1),\n",
       " (estimates, 1),\n",
       " (bodies, 1),\n",
       " (Moths, 1),\n",
       " (flies, 1),\n",
       " (bees, 1),\n",
       " (bees, 1),\n",
       " (ants, 1),\n",
       " (ants, 1),\n",
       " (elections, 1),\n",
       " (Wages, 1),\n",
       " (votes, 1),\n",
       " (doors, 1),\n",
       " (sources, 1),\n",
       " (bees, 1),\n",
       " (hours, 1),\n",
       " (authorities, 1),\n",
       " (allegations, 1),\n",
       " (passengers, 1),\n",
       " (findings, 1),\n",
       " (feet, 1),\n",
       " (wheels, 1),\n",
       " (police, 1),\n",
       " (dozens, 1),\n",
       " (articles, 1),\n",
       " (parents, 1),\n",
       " (ringleaders, 1),\n",
       " (facilities, 1),\n",
       " (police, 1),\n",
       " (authorities, 1),\n",
       " (animals, 1),\n",
       " (pellets, 1),\n",
       " (insects, 1),\n",
       " (soldiers, 1),\n",
       " (rebels, 1),\n",
       " (relations, 1),\n",
       " (residents, 1),\n",
       " (workers, 1),\n",
       " (journalists, 1),\n",
       " (people, 1),\n",
       " (migrants, 1),\n",
       " (migrants, 1),\n",
       " (citizens, 1),\n",
       " (citizens, 1),\n",
       " (protests, 1),\n",
       " (troops, 1),\n",
       " (allies, 1),\n",
       " (diseases, 1),\n",
       " (earnings, 1),\n",
       " (injuries, 1),\n",
       " (years, 1),\n",
       " (results, 1),\n",
       " (ambitions, 1),\n",
       " (things, 1),\n",
       " (media, 1),\n",
       " (police, 1),\n",
       " (negotiations, 1),\n",
       " (stumps, 1),\n",
       " (rocks, 1),\n",
       " (workers, 1),\n",
       " (trees, 1),\n",
       " (protests, 1),\n",
       " (months, 1),\n",
       " (violations, 1),\n",
       " (parties, 1),\n",
       " (months, 1),\n",
       " (insects, 1),\n",
       " (trophies, 1),\n",
       " (deployments, 1),\n",
       " (species, 1),\n",
       " (colonies, 1),\n",
       " (days, 1),\n",
       " (ants, 1),\n",
       " (nestmates, 1),\n",
       " (rights, 1),\n",
       " (activists, 1),\n",
       " (experts, 1),\n",
       " (prisons, 1),\n",
       " (tanks, 1),\n",
       " (protests, 1),\n",
       " (politics, 1),\n",
       " (borders, 1),\n",
       " (drivers, 1),\n",
       " (confessions, 1),\n",
       " (times, 1),\n",
       " (missiles, 1),\n",
       " (titles, 1),\n",
       " (titles, 1),\n",
       " (images, 1),\n",
       " (officers, 1),\n",
       " (facilities, 1),\n",
       " (operations, 1),\n",
       " (substances, 1),\n",
       " (doubts, 1),\n",
       " (citizens, 1),\n",
       " (citizens, 1),\n",
       " (hours, 1),\n",
       " (words, 1),\n",
       " (Victims, 1),\n",
       " (people, 1),\n",
       " (patrols, 1),\n",
       " (assets, 1),\n",
       " (interests, 1),\n",
       " (insects, 1),\n",
       " (broadcasts, 1),\n",
       " (broadcasts, 1),\n",
       " (vehicles, 1),\n",
       " (troops, 1),\n",
       " (owners, 1),\n",
       " (arms, 1),\n",
       " (countries, 1),\n",
       " (Officials, 1),\n",
       " (individuals, 1),\n",
       " (scientists, 1),\n",
       " (migrants, 1),\n",
       " (talks, 1),\n",
       " (times, 1),\n",
       " (strikes, 1),\n",
       " (days, 1),\n",
       " (days, 1),\n",
       " (days, 1),\n",
       " (detainees, 1),\n",
       " (prisons, 1),\n",
       " (defendants, 1),\n",
       " (police, 1),\n",
       " (sympathies, 1),\n",
       " (relatives, 1),\n",
       " (police, 1),\n",
       " (condolences, 1),\n",
       " (families, 1),\n",
       " (drivers, 1),\n",
       " (condolences, 1),\n",
       " (media, 1),\n",
       " (executions, 1),\n",
       " (officials, 1),\n",
       " (militants, 1),\n",
       " (reports, 1),\n",
       " (polls, 1),\n",
       " (companies, 1),\n",
       " (tests, 1),\n",
       " (substances, 1),\n",
       " (statements, 1),\n",
       " (affairs, 1),\n",
       " (data, 1),\n",
       " (species, 1),\n",
       " (thanks, 1),\n",
       " (ants, 1),\n",
       " (cases, 1),\n",
       " (drivers, 1),\n",
       " (speeds, 1),\n",
       " (rates, 1),\n",
       " (rates, 1),\n",
       " (jobs, 1),\n",
       " (species, 1),\n",
       " (troops, 1),\n",
       " (troops, 1),\n",
       " (Reports, 1),\n",
       " (troops, 1),\n",
       " (inmates, 1),\n",
       " (shots, 1),\n",
       " (rivals, 1),\n",
       " (mice, 1),\n",
       " (sticks, 1),\n",
       " (caps, 1),\n",
       " (gains, 1),\n",
       " (months, 1),\n",
       " (observers, 1),\n",
       " (terms, 1),\n",
       " (principles, 1),\n",
       " (leaders, 1),\n",
       " (colonies, 1),\n",
       " (ads, 1),\n",
       " (lots, 1),\n",
       " (actions, 1),\n",
       " (media, 1),\n",
       " (proceedings, 1),\n",
       " (protests, 1),\n",
       " (conservatives, 1),\n",
       " (pieces, 1),\n",
       " (candidates, 1),\n",
       " (policies, 1),\n",
       " (lives, 1),\n",
       " (troops, 1),\n",
       " (diplomats, 1),\n",
       " (sources, 1),\n",
       " (hundreds, 1),\n",
       " (thousands, 1),\n",
       " (documents, 1),\n",
       " (elections, 1),\n",
       " (troops, 1),\n",
       " (months, 1),\n",
       " (Roadworkers, 1),\n",
       " (police, 1),\n",
       " (bodies, 1),\n",
       " (weeks, 1),\n",
       " (servers, 1),\n",
       " (parties, 1),\n",
       " (termites, 1),\n",
       " (abilities, 1),\n",
       " (findings, 1),\n",
       " (reals, 1),\n",
       " (people, 1),\n",
       " (ants, 1),\n",
       " (men, 1),\n",
       " (women, 1),\n",
       " (children, 1),\n",
       " (brothers, 1),\n",
       " (arms, 1),\n",
       " (doctors, 1),\n",
       " (protests, 1),\n",
       " (concerns, 1),\n",
       " (members, 1),\n",
       " (accusations, 1),\n",
       " (women, 1),\n",
       " (candidates, 1),\n",
       " (colonies, 1),\n",
       " (ants, 1),\n",
       " (people, 1),\n",
       " (people, 1),\n",
       " (Demonstrators, 1),\n",
       " (plutocrats, 1),\n",
       " (gangs, 1),\n",
       " (parts, 1),\n",
       " (people, 1),\n",
       " (Reports, 1),\n",
       " (Hours, 1),\n",
       " (Hours, 1),\n",
       " (commits, 1),\n",
       " (members, 1),\n",
       " (pictures, 1),\n",
       " (ants, 1),\n",
       " (substances, 1),\n",
       " (dozens, 1),\n",
       " (rounds, 1),\n",
       " (witnesses, 1),\n",
       " (authorities, 1),\n",
       " (statements, 1),\n",
       " (officials, 1),\n",
       " (officials, 1),\n",
       " (men, 1),\n",
       " (debates, 1),\n",
       " (Police, 1),\n",
       " (leaks, 1),\n",
       " (secrets, 1),\n",
       " (sets, 1),\n",
       " (neurons, 1),\n",
       " (decades, 1),\n",
       " (police, 1),\n",
       " (motorists, 1),\n",
       " (people, 1),\n",
       " (neighbours, 1),\n",
       " (Hundreds, 1),\n",
       " (members, 1),\n",
       " (soldiers, 1),\n",
       " (expectations, 1),\n",
       " (debates, 1),\n",
       " (bribes, 1),\n",
       " (ants, 1),\n",
       " (ants, 1),\n",
       " (deaths, 1),\n",
       " (profundities, 1),\n",
       " (lorries, 1),\n",
       " (ants, 1),\n",
       " (enemies, 1),\n",
       " (Fronti√®res, 1),\n",
       " (troops, 1),\n",
       " (vehicles, 1),\n",
       " (troops, 1),\n",
       " (months, 1),\n",
       " (kilometers, 1),\n",
       " (minutes, 1),\n",
       " (images, 1),\n",
       " (officers, 1),\n",
       " (officers, 1),\n",
       " (murders, 1),\n",
       " (defences, 1),\n",
       " (details, 1),\n",
       " (ants, 1),\n",
       " (friends, 1),\n",
       " (Commanders, 1),\n",
       " (troops, 1),\n",
       " (operations, 1),\n",
       " (tools, 1),\n",
       " (hours, 1),\n",
       " (counteractions, 1),\n",
       " (members, 1),\n",
       " (fatalities, 1),\n",
       " (reports, 1),\n",
       " (cases, 1),\n",
       " (years, 1),\n",
       " (problems, 1),\n",
       " (locks, 1),\n",
       " (Ties, 1),\n",
       " (polls, 1),\n",
       " (loudspeakers, 1),\n",
       " (ants, 1),\n",
       " (studies, 1),\n",
       " (adaptations, 1),\n",
       " (insects, 1),\n",
       " (experiments, 1),\n",
       " (mice, 1),\n",
       " (stowaways, 1),\n",
       " (years, 1),\n",
       " (goals, 1),\n",
       " (appearances, 1),\n",
       " (goals, 1),\n",
       " (matches, 1),\n",
       " (words, 1),\n",
       " (days, 1),\n",
       " (contributions, 1),\n",
       " (media, 1),\n",
       " (media, 1),\n",
       " (tactics, 1),\n",
       " (mice, 1),\n",
       " (fibers, 1),\n",
       " (brains, 1),\n",
       " (men, 1),\n",
       " (temperatures, 1),\n",
       " (hearts, 1),\n",
       " (ants, 1),\n",
       " (chemicals, 1),\n",
       " (ants, 1),\n",
       " (ants, 1),\n",
       " (victims, 1),\n",
       " (authorities, 1),\n",
       " (troops, 1),\n",
       " (vehicles, 1),\n",
       " (years, 1),\n",
       " (laps, 1),\n",
       " (officers, 1),\n",
       " (corpses, 1),\n",
       " (police, 1),\n",
       " (corpses, 1),\n",
       " (relations, 1),\n",
       " (sets, 1),\n",
       " (neurons, 1),\n",
       " (reporters, 1),\n",
       " (men, 1),\n",
       " (articles, 1),\n",
       " (men, 1),\n",
       " (people, 1),\n",
       " (forces, 1),\n",
       " (parts, 1),\n",
       " (refugees, 1),\n",
       " (experts, 1),\n",
       " (candidates, 1),\n",
       " (candidates, 1),\n",
       " (players, 1),\n",
       " (media, 1),\n",
       " (relations, 1),\n",
       " (renderings, 1),\n",
       " (troops, 1),\n",
       " (troops, 1),\n",
       " (diplomats, 1),\n",
       " (agencies, 1),\n",
       " (guesses, 1),\n",
       " (scientists, 1),\n",
       " (animals, 1),\n",
       " (police, 1),\n",
       " (people, 1),\n",
       " (chemicals, 1),\n",
       " (aphids, 1),\n",
       " (ants, 1),\n",
       " (authorities, 1),\n",
       " (insurgents, 1),\n",
       " (provinces, 1),\n",
       " (months, 1),\n",
       " (actions, 1),\n",
       " (forms, 1),\n",
       " (buoys, 1),\n",
       " (islands, 1),\n",
       " (lines, 1),\n",
       " (accounts, 1),\n",
       " (videos, 1),\n",
       " (plans, 1),\n",
       " (insurgents, 1),\n",
       " (reports, 1),\n",
       " (prisoners, 1),\n",
       " (records, 1),\n",
       " (detainees, 1),\n",
       " (setups, 1),\n",
       " (nations, 1),\n",
       " (investigators, 1),\n",
       " (locks, 1),\n",
       " (discussions, 1),\n",
       " (cars, 1),\n",
       " (authorities, 1),\n",
       " (days, 1),\n",
       " (spores, 1),\n",
       " (spores, 1),\n",
       " (fatalities, 1),\n",
       " (ants, 1),\n",
       " (paws, 1),\n",
       " (images, 1),\n",
       " (craters, 1),\n",
       " (hands, 1),\n",
       " (times, 1),\n",
       " (researchers, 1),\n",
       " (costs, 1),\n",
       " (relations, 1),\n",
       " (troops, 1),\n",
       " (respects, 1),\n",
       " (customs, 1),\n",
       " (funds, 1),\n",
       " (abuses, 1),\n",
       " (rights, 1),\n",
       " (seaplanes, 1),\n",
       " (countries, 1),\n",
       " (militaries, 1),\n",
       " (levels, 1),\n",
       " (results, 1),\n",
       " (relations, 1),\n",
       " (resignations, 1),\n",
       " (victims, 1),\n",
       " (jobs, 1),\n",
       " (contributions, 1),\n",
       " (contributions, 1),\n",
       " (schemes, 1),\n",
       " (theories, 1),\n",
       " (inmates, 1),\n",
       " (stowaways, 1),\n",
       " (mountains, 1),\n",
       " (colonies, 1),\n",
       " (trunks, 1),\n",
       " (sites, 1),\n",
       " (occasions, 1),\n",
       " (jets, 1),\n",
       " (men, 1),\n",
       " (drivers, 1),\n",
       " (Authorities, 1),\n",
       " (others, 1),\n",
       " (claims, 1),\n",
       " (talks, 1),\n",
       " (mid-2000s, 1),\n",
       " (colleagues, 1),\n",
       " (ants, 1),\n",
       " (colors, 1),\n",
       " (explosives, 1),\n",
       " (premiers, 1),\n",
       " (industries, 1),\n",
       " (days, 1),\n",
       " (Prosecutors, 1),\n",
       " (bribes, 1),\n",
       " (injuries, 1),\n",
       " (feet, 1),\n",
       " (inches, 1),\n",
       " (executions, 1),\n",
       " (officials, 1),\n",
       " (murders, 1),\n",
       " (ants, 1),\n",
       " (defendants, 1),\n",
       " (defendants, 1),\n",
       " (ants, 1),\n",
       " (questions, 1),\n",
       " (ants, 1),\n",
       " (nationals, 1),\n",
       " (police, 1),\n",
       " (chemicals, 1),\n",
       " (men, 1),\n",
       " (jobs, 1),\n",
       " (jobs, 1),\n",
       " (nations, 1),\n",
       " (images, 1),\n",
       " (signings, 1),\n",
       " (victims, 1),\n",
       " (parts, 1),\n",
       " (results, 1),\n",
       " (areas, 1),\n",
       " (others, 1),\n",
       " (years, 1),\n",
       " (charges, 1)]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(universal_dict['NNS']).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "7b5309ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "cb0b4e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_dict['NNS']\n",
    "def Most_Common(lst):\n",
    "    text = []\n",
    "    for item in lst:\n",
    "        text.append(item.text)\n",
    "    \n",
    "    list_of_words=text\n",
    "    c = Counter(list_of_words)\n",
    "    c.most_common(1)\n",
    "    return c.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "71f73fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getstat(key, length):\n",
    "    data = universal_dict[key]\n",
    "    \n",
    "    count = len(data)\n",
    "    freq = count/length\n",
    "    \n",
    "    \n",
    "    commons = Most_Common(data)\n",
    "    most = commons[0:3]\n",
    "    least=commons[-1]\n",
    "    \n",
    "    return pd.DataFrame({'Finegrained':key, 'Universal':key, 'Occurences':count, 'Relative':freq,\n",
    "             'Most frequent':most, 'Least frequent':least})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "0018d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 0\n",
    "for key in universal_dict.keys():\n",
    "    length += len(universal_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "452aaba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "32b8ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame({'Finegrained':[], 'Universal':[], 'Occurences':[], 'Relative':[],\n",
    "             'Most frequent':[], 'Least frequent':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "e07a12a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5200/563057186.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgetstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5200/3208057702.py\u001b[0m in \u001b[0;36mgetstat\u001b[1;34m(key, length)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mleast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcommons\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     return pd.DataFrame({'Finegrained':key, 'Universal':key, 'Occurences':count, 'Relative':freq,\n\u001b[0m\u001b[0;32m     13\u001b[0m              'Most frequent':most, 'Least frequent':least})\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m     return arrays_to_mgr(\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "getstat(key, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "adac419f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5200/4030525625.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0muniversal_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5200/3208057702.py\u001b[0m in \u001b[0;36mgetstat\u001b[1;34m(key, length)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mleast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcommons\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     return pd.DataFrame({'Finegrained':key, 'Universal':key, 'Occurences':count, 'Relative':freq,\n\u001b[0m\u001b[0;32m     13\u001b[0m              'Most frequent':most, 'Least frequent':least})\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m     return arrays_to_mgr(\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "for key in universal_dict.keys():\n",
    "    pd.concat([table, getstat(key, length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "9576fae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Finegrained': 'NN',\n",
       " 'Universal': 'NN',\n",
       " 'Occurences': 2074,\n",
       " 'Relative': 0.12858028518288903,\n",
       " 'Most frequent': [('\\\\', 52), ('year', 29), ('report', 23)],\n",
       " 'Least frequent': ('project', 1)}"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getstat('NN', length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "c146b02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Finegrained</th>\n",
       "      <th>Universal</th>\n",
       "      <th>Occurences</th>\n",
       "      <th>Relative</th>\n",
       "      <th>Most frequent</th>\n",
       "      <th>Least frequent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Finegrained, Universal, Occurences, Relative, Most frequent, Least frequent]\n",
       "Index: []"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3717922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
